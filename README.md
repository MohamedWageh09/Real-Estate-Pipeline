# Real Estate Data Engineering Project

## Overview
This project is a **data engineering pipeline** that extracts, processes, and stores real estate listings from property-selling websites like **Property Finder** and **Bayut**. The goal is to **scrape, clean, and store real estate data** into a **PostgreSQL database**, utilizing **Apache Spark** for scalable data processing.

## Tech Stack
- **Python** â†’ Web Scraping & Data Processing  
- **Apache Spark** â†’ Distributed Data Processing  
- **PostgreSQL** â†’ Data Storage  
- **Docker & Docker Compose** â†’ Containerization  

---

## Project Structure
```
real-estate-data-engineering
â”œâ”€â”€ data                 
â”œâ”€â”€ Dockerfile             
â”œâ”€â”€ docker-compose    
â”œâ”€â”€ scrapper.py           
â”œâ”€â”€ preprocessing.py        
â”œâ”€â”€ load_data.py            
â”œâ”€â”€ main.py                 
â”œâ”€â”€ requirements.txt        
â””â”€â”€ README.md                 
```

---

## ğŸ› How It Works

### **1ï¸âƒ£ Web Scraping (`scrapper.py`)**  
- Scrapes real estate listings from **Property Finder** and **Bayut**.  
- Extracts data like **title, price, location, size, bedrooms, bathrooms, and URL**.  
- Saves raw data in the `/data` folder.  

### **2ï¸âƒ£ Data Processing (`preprocessing.py`)**  
- Uses **Apache Spark** to clean and transform the scraped data.  
- Handles **missing values, duplicates, and data formatting**.
- Applying some logic such as extracting the sub-location from location. 

### **3ï¸âƒ£ Loading Data (`load_data.py`)**  
- Connects to **PostgreSQL** and creates a table.  
- Loads the cleaned data into the database.  

### **4ï¸âƒ£ Running the Pipeline (`main.py`)**  
- Runs all scripts **in sequence** to complete the pipeline.  

---

```

## Future Improvements
- [ ] Automate daily data scraping
- [ ] Add machine learning model for price prediction  

